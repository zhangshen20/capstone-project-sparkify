{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import avg, col, concat, desc, explode, \\\n",
    "        lit, min, max, sum, count, split, udf, to_date, from_unixtime, datediff, when, countDistinct, date_add\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import types\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_past_N_days(df: DataFrame, \\\n",
    "                        days: types.IntegerType, \\\n",
    "                        date_col_event: types.StringType) -> DataFrame:\n",
    "    ''' Extract past N days data from a dataframe\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): a dataframe\n",
    "        days (Integer): a number of days\n",
    "        date_col_event (String): date column name used to check if a record is within the date range\n",
    "    Returns:\n",
    "        df_new: a dataframe contains only specitifed days' data\n",
    "    \n",
    "    '''\n",
    "    try:\n",
    "        df_max_date = df.groupBy('userId').agg(max(date_col_event).alias('date_to'))\n",
    "        \n",
    "        df_new = \\\n",
    "            df.join(df_max_date, on='userId', how='inner') \\\n",
    "              .where(datediff(col('date_to'), col(date_col_event)) < days) \\\n",
    "              .withColumn('date_from', \\\n",
    "                          when(datediff(col('date_to'), col('registration_date')) < days, col('registration_date')).otherwise(date_add(col('date_to'), -1*days+1)) \\\n",
    "                         )\n",
    "        \n",
    "    except Py4JJavaError as e:\n",
    "        \n",
    "        df_new = sc.emptyRDD()\n",
    "        \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize_Data_ToUser(df: DataFrame) -> DataFrame:\n",
    "    '''Normalize Raw dataframe to User Based. After this transformation, each record will be usedId based. \n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): raw data frame\n",
    "        \n",
    "    Returns:\n",
    "        df_new (DataFrame): normalized dataframe (user-based)\n",
    "    '''\n",
    "\n",
    "    df_userId = df.groupBy('userId')\n",
    "\n",
    "    df_days = \\\n",
    "        df_userId.agg(countDistinct('event_date').alias('num_active_days'), \\\n",
    "                      min('date_from').alias('date_from'),                  \\\n",
    "                      max('date_to').alias('date_to'),                      \\\n",
    "                      min('registration_date').alias('registration_date')   \\\n",
    "                      )\n",
    "    df_current_level = \\\n",
    "        df.where(col('event_date') == col('date_to')) \\\n",
    "          .groupBy('userId') \\\n",
    "          .agg(min('level').alias('current_level')) \\\n",
    "          .withColumn('current_level_paid', when(col('current_level') == 'paid', 1).otherwise(0))\n",
    "    \n",
    "    df_pages = \\\n",
    "        df_userId.pivot(\"page\") \\\n",
    "           .agg(count('page'))    \n",
    "    \n",
    "    df_songs = \\\n",
    "        df.where(col('page') == 'NextSong') \\\n",
    "          .groupBy('userId') \\\n",
    "          .agg(count('page').alias('num_songs'), countDistinct('song').alias('num_songs_unique'))\n",
    "\n",
    "    df_artists = \\\n",
    "        df.where(col('page') == 'NextSong') \\\n",
    "          .groupBy('userId') \\\n",
    "          .agg(countDistinct('artist').alias('num_artist'), \\\n",
    "               sum('length').alias('total_play_length') \\\n",
    "              )    \n",
    "\n",
    "    df_active_days_as_paid = \\\n",
    "        df.where(col('level') == 'paid').groupBy('userId') \\\n",
    "          .agg(countDistinct('event_date').alias('num_active_days_paid'))\n",
    "\n",
    "    df_new = \\\n",
    "        df_songs.join(df_artists, on='userId', how='left') \\\n",
    "                .join(df_days, on='userId', how='left') \\\n",
    "                .join(df_active_days_as_paid, on='userId', how='left') \\\n",
    "                .join(df_pages, on='userId', how='left') \\\n",
    "                .join(df_current_level, on='userId', how='left') \\\n",
    "                .select(col('*'), \\\n",
    "                        (datediff(col('date_to'), col('registration_date'))+1).alias('days_since_registration'), \\\n",
    "                        (datediff(col('date_to'), col('date_from'))+1).alias('days_in_member') ) \\\n",
    "                .withColumn('active_pct', (col('num_active_days') / col('days_in_member'))) \\\n",
    "                .withColumn('avg_songs_per_day', col('num_songs') / col('days_in_member')) \\\n",
    "                .withColumn('avg_songs_per_active_day', col('num_songs') / col('num_active_days')) \\\n",
    "                .withColumn('avg_play_length_per_day', col('total_play_length') / col('days_in_member')) \\\n",
    "                .withColumn('avg_play_length_per_active_day', col('total_play_length') / col('num_active_days')) \n",
    "\n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_Churn_Flag(df: DataFrame, df_churn: DataFrame) -> DataFrame:\n",
    "    '''Add 'Churn' flag to df\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): normalized dataframe\n",
    "        df_churn (DataFrame): list of churn users \n",
    "        \n",
    "    Return:\n",
    "        df_new (DataFrame): new dataframe with a churn flag value -> 1\n",
    "    '''\n",
    "    \n",
    "    df_new = df.join(df_churn, on='userId', how='left') \\\n",
    "               .withColumn('churn', when(col('churn') == 1, 1).otherwise(0))\n",
    "    \n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Choose_Features(df: DataFrame, cols: list) -> DataFrame:\n",
    "    '''Choose Features from Dataframe\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): normalized dataframe\n",
    "        cols (list): list of columns to be extracted\n",
    "        \n",
    "    Return:\n",
    "        df_new (DataFrame): new dataframe with selected features\n",
    "    '''\n",
    "\n",
    "    cols = ['userId', 'churn'] + cols           \n",
    "\n",
    "    df_new = df.select(cols).na.fill(0)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Choose_Features_Pandas(df_pd, cols):\n",
    "    '''Choose Features from Dataframe\n",
    "    \n",
    "    Parameters:\n",
    "        df (Pandas DataFrame): normalized dataframe\n",
    "        cols (list): list of columns to be extracted\n",
    "        \n",
    "    Return:\n",
    "        df_new (DataFrame): new dataframe with selected features\n",
    "    '''\n",
    "\n",
    "    cols = ['userId', 'churn'] + cols           \n",
    "\n",
    "    df_new = df_pd[cols].fillna(0)\n",
    "    \n",
    "    return df_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
